{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bank_churn_nn_bhavinshah.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"code","metadata":{"id":"HkwMFEkiG_36","executionInfo":{"status":"ok","timestamp":1606008225480,"user_tz":360,"elapsed":2195,"user":{"displayName":"Bhavin Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP8kt4VFEDIIcPCxa1ZEDORGzYvFZvILuDA5C--g=s64","userId":"18232631185571279481"}}},"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from sklearn import preprocessing\n","from tensorflow.keras.models import Sequential\n","from sklearn.preprocessing import StandardScaler\n","from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n","from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve, auc\n","import matplotlib.pyplot as plt\n","from tensorflow.keras import optimizers"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"CNxYwZyHHMd1","executionInfo":{"status":"ok","timestamp":1606008225481,"user_tz":360,"elapsed":2184,"user":{"displayName":"Bhavin Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP8kt4VFEDIIcPCxa1ZEDORGzYvFZvILuDA5C--g=s64","userId":"18232631185571279481"}}},"source":["from google.colab import drive"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sZPRfM6QHPVJ","executionInfo":{"status":"ok","timestamp":1606008225481,"user_tz":360,"elapsed":2177,"user":{"displayName":"Bhavin Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP8kt4VFEDIIcPCxa1ZEDORGzYvFZvILuDA5C--g=s64","userId":"18232631185571279481"}},"outputId":"4116dd98-8939-497a-8691-4072ef86c946"},"source":["drive.mount('/content/drive/')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PDHl1pPZHYqF","executionInfo":{"status":"ok","timestamp":1606008225482,"user_tz":360,"elapsed":2171,"user":{"displayName":"Bhavin Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP8kt4VFEDIIcPCxa1ZEDORGzYvFZvILuDA5C--g=s64","userId":"18232631185571279481"}}},"source":["project_path = '/content/drive/My Drive/aiml/'"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"uZaWCnBsJkNz","executionInfo":{"status":"ok","timestamp":1606008225483,"user_tz":360,"elapsed":2167,"user":{"displayName":"Bhavin Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP8kt4VFEDIIcPCxa1ZEDORGzYvFZvILuDA5C--g=s64","userId":"18232631185571279481"}}},"source":["dataset_file = project_path + 'bank.csv'"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Sxoox_4bSXbL"},"source":["### 1. Read the dataset"]},{"cell_type":"code","metadata":{"id":"yynB0BQJMXGW","executionInfo":{"status":"ok","timestamp":1606008225484,"user_tz":360,"elapsed":2164,"user":{"displayName":"Bhavin Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP8kt4VFEDIIcPCxa1ZEDORGzYvFZvILuDA5C--g=s64","userId":"18232631185571279481"}}},"source":["data = pd.read_csv(dataset_file)\n","#data = pd.read_csv('bank.csv')"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"iscIcLYzMZ9q","executionInfo":{"status":"ok","timestamp":1606008225670,"user_tz":360,"elapsed":2341,"user":{"displayName":"Bhavin Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP8kt4VFEDIIcPCxa1ZEDORGzYvFZvILuDA5C--g=s64","userId":"18232631185571279481"}},"outputId":"20332c26-c9f7-4fd2-b77c-5d84db891cae"},"source":["data.head()"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>RowNumber</th>\n","      <th>CustomerId</th>\n","      <th>Surname</th>\n","      <th>CreditScore</th>\n","      <th>Geography</th>\n","      <th>Gender</th>\n","      <th>Age</th>\n","      <th>Tenure</th>\n","      <th>Balance</th>\n","      <th>NumOfProducts</th>\n","      <th>HasCrCard</th>\n","      <th>IsActiveMember</th>\n","      <th>EstimatedSalary</th>\n","      <th>Exited</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>15634602</td>\n","      <td>Hargrave</td>\n","      <td>619</td>\n","      <td>France</td>\n","      <td>Female</td>\n","      <td>42</td>\n","      <td>2</td>\n","      <td>0.00</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>101348.88</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>15647311</td>\n","      <td>Hill</td>\n","      <td>608</td>\n","      <td>Spain</td>\n","      <td>Female</td>\n","      <td>41</td>\n","      <td>1</td>\n","      <td>83807.86</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>112542.58</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>15619304</td>\n","      <td>Onio</td>\n","      <td>502</td>\n","      <td>France</td>\n","      <td>Female</td>\n","      <td>42</td>\n","      <td>8</td>\n","      <td>159660.80</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113931.57</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>15701354</td>\n","      <td>Boni</td>\n","      <td>699</td>\n","      <td>France</td>\n","      <td>Female</td>\n","      <td>39</td>\n","      <td>1</td>\n","      <td>0.00</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>93826.63</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>15737888</td>\n","      <td>Mitchell</td>\n","      <td>850</td>\n","      <td>Spain</td>\n","      <td>Female</td>\n","      <td>43</td>\n","      <td>2</td>\n","      <td>125510.82</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>79084.10</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   RowNumber  CustomerId   Surname  ...  IsActiveMember EstimatedSalary Exited\n","0          1    15634602  Hargrave  ...               1       101348.88      1\n","1          2    15647311      Hill  ...               1       112542.58      0\n","2          3    15619304      Onio  ...               0       113931.57      1\n","3          4    15701354      Boni  ...               0        93826.63      0\n","4          5    15737888  Mitchell  ...               1        79084.10      0\n","\n","[5 rows x 14 columns]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"izjuv46-SXbM"},"source":["### 2. Drop the columns which are unique for all users like IDs"]},{"cell_type":"code","metadata":{"id":"mJlHvHKYMia_","executionInfo":{"status":"ok","timestamp":1606008225671,"user_tz":360,"elapsed":2335,"user":{"displayName":"Bhavin Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP8kt4VFEDIIcPCxa1ZEDORGzYvFZvILuDA5C--g=s64","userId":"18232631185571279481"}}},"source":["df1 = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"FDEKrxudXeQQ","executionInfo":{"status":"ok","timestamp":1606008225671,"user_tz":360,"elapsed":2328,"user":{"displayName":"Bhavin Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP8kt4VFEDIIcPCxa1ZEDORGzYvFZvILuDA5C--g=s64","userId":"18232631185571279481"}}},"source":["df2 = pd.get_dummies(data=df1, columns=['Geography', 'Gender'], drop_first = True)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gi3HiKTNSXbM"},"source":["### 3. Distinguish the feature and test sets"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"BsuRxNSBg-ZM","executionInfo":{"status":"ok","timestamp":1606008225672,"user_tz":360,"elapsed":2322,"user":{"displayName":"Bhavin Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP8kt4VFEDIIcPCxa1ZEDORGzYvFZvILuDA5C--g=s64","userId":"18232631185571279481"}},"outputId":"850637fc-e6a5-432d-c471-32be705222ea"},"source":["df2.head()"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>CreditScore</th>\n","      <th>Age</th>\n","      <th>Tenure</th>\n","      <th>Balance</th>\n","      <th>NumOfProducts</th>\n","      <th>HasCrCard</th>\n","      <th>IsActiveMember</th>\n","      <th>EstimatedSalary</th>\n","      <th>Exited</th>\n","      <th>Geography_Germany</th>\n","      <th>Geography_Spain</th>\n","      <th>Gender_Male</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>619</td>\n","      <td>42</td>\n","      <td>2</td>\n","      <td>0.00</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>101348.88</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>608</td>\n","      <td>41</td>\n","      <td>1</td>\n","      <td>83807.86</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>112542.58</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>502</td>\n","      <td>42</td>\n","      <td>8</td>\n","      <td>159660.80</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113931.57</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>699</td>\n","      <td>39</td>\n","      <td>1</td>\n","      <td>0.00</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>93826.63</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>850</td>\n","      <td>43</td>\n","      <td>2</td>\n","      <td>125510.82</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>79084.10</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   CreditScore  Age  Tenure  ...  Geography_Germany  Geography_Spain  Gender_Male\n","0          619   42       2  ...                  0                0            0\n","1          608   41       1  ...                  0                1            0\n","2          502   42       8  ...                  0                0            0\n","3          699   39       1  ...                  0                0            0\n","4          850   43       2  ...                  0                1            0\n","\n","[5 rows x 12 columns]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":317},"id":"Cer1gDHHM1hp","executionInfo":{"status":"ok","timestamp":1606008225673,"user_tz":360,"elapsed":2306,"user":{"displayName":"Bhavin Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP8kt4VFEDIIcPCxa1ZEDORGzYvFZvILuDA5C--g=s64","userId":"18232631185571279481"}},"outputId":"e1a47893-24ea-4d45-9237-145e112acbba"},"source":["df2.describe()"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>CreditScore</th>\n","      <th>Age</th>\n","      <th>Tenure</th>\n","      <th>Balance</th>\n","      <th>NumOfProducts</th>\n","      <th>HasCrCard</th>\n","      <th>IsActiveMember</th>\n","      <th>EstimatedSalary</th>\n","      <th>Exited</th>\n","      <th>Geography_Germany</th>\n","      <th>Geography_Spain</th>\n","      <th>Gender_Male</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.00000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","      <td>10000.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>650.528800</td>\n","      <td>38.921800</td>\n","      <td>5.012800</td>\n","      <td>76485.889288</td>\n","      <td>1.530200</td>\n","      <td>0.70550</td>\n","      <td>0.515100</td>\n","      <td>100090.239881</td>\n","      <td>0.203700</td>\n","      <td>0.250900</td>\n","      <td>0.247700</td>\n","      <td>0.545700</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>96.653299</td>\n","      <td>10.487806</td>\n","      <td>2.892174</td>\n","      <td>62397.405202</td>\n","      <td>0.581654</td>\n","      <td>0.45584</td>\n","      <td>0.499797</td>\n","      <td>57510.492818</td>\n","      <td>0.402769</td>\n","      <td>0.433553</td>\n","      <td>0.431698</td>\n","      <td>0.497932</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>350.000000</td>\n","      <td>18.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>11.580000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>584.000000</td>\n","      <td>32.000000</td>\n","      <td>3.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>51002.110000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>652.000000</td>\n","      <td>37.000000</td>\n","      <td>5.000000</td>\n","      <td>97198.540000</td>\n","      <td>1.000000</td>\n","      <td>1.00000</td>\n","      <td>1.000000</td>\n","      <td>100193.915000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>718.000000</td>\n","      <td>44.000000</td>\n","      <td>7.000000</td>\n","      <td>127644.240000</td>\n","      <td>2.000000</td>\n","      <td>1.00000</td>\n","      <td>1.000000</td>\n","      <td>149388.247500</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>850.000000</td>\n","      <td>92.000000</td>\n","      <td>10.000000</td>\n","      <td>250898.090000</td>\n","      <td>4.000000</td>\n","      <td>1.00000</td>\n","      <td>1.000000</td>\n","      <td>199992.480000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        CreditScore           Age  ...  Geography_Spain   Gender_Male\n","count  10000.000000  10000.000000  ...     10000.000000  10000.000000\n","mean     650.528800     38.921800  ...         0.247700      0.545700\n","std       96.653299     10.487806  ...         0.431698      0.497932\n","min      350.000000     18.000000  ...         0.000000      0.000000\n","25%      584.000000     32.000000  ...         0.000000      0.000000\n","50%      652.000000     37.000000  ...         0.000000      1.000000\n","75%      718.000000     44.000000  ...         0.000000      1.000000\n","max      850.000000     92.000000  ...         1.000000      1.000000\n","\n","[8 rows x 12 columns]"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rINxkrwsM8po","executionInfo":{"status":"ok","timestamp":1606008225675,"user_tz":360,"elapsed":2300,"user":{"displayName":"Bhavin Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP8kt4VFEDIIcPCxa1ZEDORGzYvFZvILuDA5C--g=s64","userId":"18232631185571279481"}},"outputId":"fb281512-faf6-459c-f24c-68db079ff27a"},"source":["df2.info()"],"execution_count":12,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 10000 entries, 0 to 9999\n","Data columns (total 12 columns):\n"," #   Column             Non-Null Count  Dtype  \n","---  ------             --------------  -----  \n"," 0   CreditScore        10000 non-null  int64  \n"," 1   Age                10000 non-null  int64  \n"," 2   Tenure             10000 non-null  int64  \n"," 3   Balance            10000 non-null  float64\n"," 4   NumOfProducts      10000 non-null  int64  \n"," 5   HasCrCard          10000 non-null  int64  \n"," 6   IsActiveMember     10000 non-null  int64  \n"," 7   EstimatedSalary    10000 non-null  float64\n"," 8   Exited             10000 non-null  int64  \n"," 9   Geography_Germany  10000 non-null  uint8  \n"," 10  Geography_Spain    10000 non-null  uint8  \n"," 11  Gender_Male        10000 non-null  uint8  \n","dtypes: float64(2), int64(7), uint8(3)\n","memory usage: 732.5 KB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"a2lounOvNMWL","executionInfo":{"status":"ok","timestamp":1606008225676,"user_tz":360,"elapsed":2295,"user":{"displayName":"Bhavin Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP8kt4VFEDIIcPCxa1ZEDORGzYvFZvILuDA5C--g=s64","userId":"18232631185571279481"}}},"source":["y_data = df2['Exited']"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iOtosWKCNV52","executionInfo":{"status":"ok","timestamp":1606008225676,"user_tz":360,"elapsed":2289,"user":{"displayName":"Bhavin Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP8kt4VFEDIIcPCxa1ZEDORGzYvFZvILuDA5C--g=s64","userId":"18232631185571279481"}},"outputId":"20614f5d-444a-4a07-c5bd-929f0a996af8"},"source":["y_data"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0       1\n","1       0\n","2       1\n","3       0\n","4       0\n","       ..\n","9995    0\n","9996    0\n","9997    1\n","9998    1\n","9999    0\n","Name: Exited, Length: 10000, dtype: int64"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p5OOMAFT7SSO","executionInfo":{"status":"ok","timestamp":1606008225844,"user_tz":360,"elapsed":2447,"user":{"displayName":"Bhavin Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP8kt4VFEDIIcPCxa1ZEDORGzYvFZvILuDA5C--g=s64","userId":"18232631185571279481"}},"outputId":"ffe2ed15-33d1-4ec7-fd78-93c2015c309b"},"source":["y_data.value_counts()"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    7963\n","1    2037\n","Name: Exited, dtype: int64"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"Qa0ZFCyaNYjV","executionInfo":{"status":"ok","timestamp":1606008225847,"user_tz":360,"elapsed":2444,"user":{"displayName":"Bhavin Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP8kt4VFEDIIcPCxa1ZEDORGzYvFZvILuDA5C--g=s64","userId":"18232631185571279481"}}},"source":["X_data = df2.drop(['Exited'], axis = 1)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"mIEUV7A1NcfA","executionInfo":{"status":"ok","timestamp":1606008225849,"user_tz":360,"elapsed":2430,"user":{"displayName":"Bhavin Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP8kt4VFEDIIcPCxa1ZEDORGzYvFZvILuDA5C--g=s64","userId":"18232631185571279481"}},"outputId":"210aa485-f179-4127-b033-6cd7514edcc0"},"source":["X_data.head()"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>CreditScore</th>\n","      <th>Age</th>\n","      <th>Tenure</th>\n","      <th>Balance</th>\n","      <th>NumOfProducts</th>\n","      <th>HasCrCard</th>\n","      <th>IsActiveMember</th>\n","      <th>EstimatedSalary</th>\n","      <th>Geography_Germany</th>\n","      <th>Geography_Spain</th>\n","      <th>Gender_Male</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>619</td>\n","      <td>42</td>\n","      <td>2</td>\n","      <td>0.00</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>101348.88</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>608</td>\n","      <td>41</td>\n","      <td>1</td>\n","      <td>83807.86</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>112542.58</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>502</td>\n","      <td>42</td>\n","      <td>8</td>\n","      <td>159660.80</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113931.57</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>699</td>\n","      <td>39</td>\n","      <td>1</td>\n","      <td>0.00</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>93826.63</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>850</td>\n","      <td>43</td>\n","      <td>2</td>\n","      <td>125510.82</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>79084.10</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   CreditScore  Age  Tenure  ...  Geography_Germany  Geography_Spain  Gender_Male\n","0          619   42       2  ...                  0                0            0\n","1          608   41       1  ...                  0                1            0\n","2          502   42       8  ...                  0                0            0\n","3          699   39       1  ...                  0                0            0\n","4          850   43       2  ...                  0                1            0\n","\n","[5 rows x 11 columns]"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VUyyEHw0NfYf","executionInfo":{"status":"ok","timestamp":1606008225851,"user_tz":360,"elapsed":2410,"user":{"displayName":"Bhavin Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP8kt4VFEDIIcPCxa1ZEDORGzYvFZvILuDA5C--g=s64","userId":"18232631185571279481"}},"outputId":"9b37ab28-f5aa-45b7-d99d-cc1c185d1d02"},"source":["X_data.shape"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000, 11)"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"-J5GlaArSXbN"},"source":["### 4. Divide the data set into training and test set"]},{"cell_type":"code","metadata":{"id":"PtFduKQLNixZ","executionInfo":{"status":"ok","timestamp":1606008225853,"user_tz":360,"elapsed":2404,"user":{"displayName":"Bhavin Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP8kt4VFEDIIcPCxa1ZEDORGzYvFZvILuDA5C--g=s64","userId":"18232631185571279481"}}},"source":["X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.2, random_state = 7)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TFuh9VJVSXbN","executionInfo":{"status":"ok","timestamp":1606008225855,"user_tz":360,"elapsed":2396,"user":{"displayName":"Bhavin Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP8kt4VFEDIIcPCxa1ZEDORGzYvFZvILuDA5C--g=s64","userId":"18232631185571279481"}},"outputId":"552231b6-419d-40e5-a97f-22e83ced5ee3"},"source":["print(X_train.shape)\n","print(X_test.shape)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["(8000, 11)\n","(2000, 11)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1nreuUd7SXbN"},"source":["### 5. Normalize the train and test data"]},{"cell_type":"code","metadata":{"id":"WBA9VA8wOleu","executionInfo":{"status":"ok","timestamp":1606008225856,"user_tz":360,"elapsed":2386,"user":{"displayName":"Bhavin Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP8kt4VFEDIIcPCxa1ZEDORGzYvFZvILuDA5C--g=s64","userId":"18232631185571279481"}}},"source":["#Started with normalizer but didn't yield good result so decided to go with StandardScaler with F1 Score of 0.\n","#After changing the axis=0 for normalization, I got F1 of 0.47. But still not optimal so moved to using StandardScaler.\n","#X_train = preprocessing.normalize(X_train, axis=0)\n","#X_test = preprocessing.normalize(X_test, axis=0)\n","\n","#With StandardScalar, I can get the F1 score of 0.59 as opposed to above normalize of 0.47\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.fit_transform(X_test)"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_9NxaiTiSXbN"},"source":["### 6. Initialize & build the model. Identify the points of improvements and implement the same."]},{"cell_type":"code","metadata":{"id":"wD2aI7SsNp7a","executionInfo":{"status":"ok","timestamp":1606008225856,"user_tz":360,"elapsed":2378,"user":{"displayName":"Bhavin Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP8kt4VFEDIIcPCxa1ZEDORGzYvFZvILuDA5C--g=s64","userId":"18232631185571279481"}}},"source":["model = Sequential()"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"AllTws0qNssr","executionInfo":{"status":"ok","timestamp":1606008226055,"user_tz":360,"elapsed":2572,"user":{"displayName":"Bhavin Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP8kt4VFEDIIcPCxa1ZEDORGzYvFZvILuDA5C--g=s64","userId":"18232631185571279481"}}},"source":["# Tried many combinaton of using various activation functions (relu, tanh, swish and sigmoid)\n","# relu and swish are the best activation function out of all.\n","# Tried to have one, two and three hidden layers. Found having two hidden layers are the best.\n","# Also, tried different units for each hidden layer, but found having 6 units for the first hidden layer\n","# and 3 units for the second hidden layer. \n","# Also, tried adding the third hidden layer, but numbers degraded.\n","\n","# I have found following is the best model.\n","\n","# Please find some of the results at the end.\n","\n","model.add(Dense(6, input_shape = (X_train.shape[1],), activation = 'relu'))\n","model.add(Dense(3, activation = 'relu'))\n","#model.add(Dense(4, activation = 'relu'))\n","model.add(Dense(1, activation = 'sigmoid'))"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"W3HXMrDrNxK-","executionInfo":{"status":"ok","timestamp":1606008226056,"user_tz":360,"elapsed":2567,"user":{"displayName":"Bhavin Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP8kt4VFEDIIcPCxa1ZEDORGzYvFZvILuDA5C--g=s64","userId":"18232631185571279481"}}},"source":["\n","#Adam is giving val_accuracy compare to other. I tried sgd and adamax with F1 score of 0.58. Adadelta is worst.\n","#But, adam gave 0.59 so sticking with adam\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iA-7jSaSNznn","executionInfo":{"status":"ok","timestamp":1606008226059,"user_tz":360,"elapsed":2562,"user":{"displayName":"Bhavin Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP8kt4VFEDIIcPCxa1ZEDORGzYvFZvILuDA5C--g=s64","userId":"18232631185571279481"}},"outputId":"fc4f536e-0ba7-42fc-cd09-8cf87885cd61"},"source":["model.summary()"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense (Dense)                (None, 6)                 72        \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 3)                 21        \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1)                 4         \n","=================================================================\n","Total params: 97\n","Trainable params: 97\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JWLPKxtSJcTi","executionInfo":{"status":"ok","timestamp":1606008226060,"user_tz":360,"elapsed":2547,"user":{"displayName":"Bhavin Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP8kt4VFEDIIcPCxa1ZEDORGzYvFZvILuDA5C--g=s64","userId":"18232631185571279481"}},"outputId":"fc51a704-8a85-46b8-944d-71c70cea1ffa"},"source":["y_train.value_counts()"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    6374\n","1    1626\n","Name: Exited, dtype: int64"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sr4Hhj80N3ES","executionInfo":{"status":"ok","timestamp":1606008278931,"user_tz":360,"elapsed":55408,"user":{"displayName":"Bhavin Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP8kt4VFEDIIcPCxa1ZEDORGzYvFZvILuDA5C--g=s64","userId":"18232631185571279481"}},"outputId":"500237db-c34e-472c-aa99-de700f4e311c"},"source":["# I tried with epochs value of 40, 100, 200. 200 is giving the best F1 score so using this.\n","\n","model.fit(X_train, y_train.values, 32, epochs = 200, verbose = 1, validation_split=0.1)"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Epoch 1/200\n","225/225 [==============================] - 0s 2ms/step - loss: 0.7133 - accuracy: 0.6761 - val_loss: 0.6028 - val_accuracy: 0.7912\n","Epoch 2/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.5394 - accuracy: 0.7919 - val_loss: 0.4762 - val_accuracy: 0.8025\n","Epoch 3/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.4664 - accuracy: 0.8056 - val_loss: 0.4474 - val_accuracy: 0.8163\n","Epoch 4/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.4449 - accuracy: 0.8131 - val_loss: 0.4332 - val_accuracy: 0.8250\n","Epoch 5/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.4285 - accuracy: 0.8207 - val_loss: 0.4178 - val_accuracy: 0.8300\n","Epoch 6/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.4124 - accuracy: 0.8310 - val_loss: 0.4020 - val_accuracy: 0.8500\n","Epoch 7/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3965 - accuracy: 0.8399 - val_loss: 0.3911 - val_accuracy: 0.8475\n","Epoch 8/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3832 - accuracy: 0.8475 - val_loss: 0.3812 - val_accuracy: 0.8525\n","Epoch 9/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3734 - accuracy: 0.8519 - val_loss: 0.3752 - val_accuracy: 0.8537\n","Epoch 10/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3667 - accuracy: 0.8532 - val_loss: 0.3707 - val_accuracy: 0.8600\n","Epoch 11/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3616 - accuracy: 0.8554 - val_loss: 0.3672 - val_accuracy: 0.8600\n","Epoch 12/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3579 - accuracy: 0.8560 - val_loss: 0.3648 - val_accuracy: 0.8587\n","Epoch 13/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3554 - accuracy: 0.8568 - val_loss: 0.3620 - val_accuracy: 0.8562\n","Epoch 14/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3527 - accuracy: 0.8560 - val_loss: 0.3607 - val_accuracy: 0.8562\n","Epoch 15/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3505 - accuracy: 0.8579 - val_loss: 0.3596 - val_accuracy: 0.8525\n","Epoch 16/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3486 - accuracy: 0.8592 - val_loss: 0.3587 - val_accuracy: 0.8525\n","Epoch 17/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3474 - accuracy: 0.8593 - val_loss: 0.3585 - val_accuracy: 0.8537\n","Epoch 18/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3461 - accuracy: 0.8604 - val_loss: 0.3575 - val_accuracy: 0.8500\n","Epoch 19/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3452 - accuracy: 0.8600 - val_loss: 0.3572 - val_accuracy: 0.8512\n","Epoch 20/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3441 - accuracy: 0.8612 - val_loss: 0.3574 - val_accuracy: 0.8537\n","Epoch 21/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3439 - accuracy: 0.8592 - val_loss: 0.3569 - val_accuracy: 0.8500\n","Epoch 22/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3435 - accuracy: 0.8610 - val_loss: 0.3570 - val_accuracy: 0.8550\n","Epoch 23/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3426 - accuracy: 0.8600 - val_loss: 0.3563 - val_accuracy: 0.8512\n","Epoch 24/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3422 - accuracy: 0.8603 - val_loss: 0.3559 - val_accuracy: 0.8512\n","Epoch 25/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3419 - accuracy: 0.8615 - val_loss: 0.3554 - val_accuracy: 0.8525\n","Epoch 26/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3416 - accuracy: 0.8600 - val_loss: 0.3556 - val_accuracy: 0.8525\n","Epoch 27/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3412 - accuracy: 0.8606 - val_loss: 0.3552 - val_accuracy: 0.8525\n","Epoch 28/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3409 - accuracy: 0.8607 - val_loss: 0.3547 - val_accuracy: 0.8525\n","Epoch 29/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3408 - accuracy: 0.8606 - val_loss: 0.3539 - val_accuracy: 0.8537\n","Epoch 30/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3404 - accuracy: 0.8615 - val_loss: 0.3537 - val_accuracy: 0.8575\n","Epoch 31/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3400 - accuracy: 0.8604 - val_loss: 0.3532 - val_accuracy: 0.8562\n","Epoch 32/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3398 - accuracy: 0.8615 - val_loss: 0.3523 - val_accuracy: 0.8562\n","Epoch 33/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3395 - accuracy: 0.8604 - val_loss: 0.3522 - val_accuracy: 0.8550\n","Epoch 34/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3394 - accuracy: 0.8597 - val_loss: 0.3528 - val_accuracy: 0.8550\n","Epoch 35/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3392 - accuracy: 0.8610 - val_loss: 0.3519 - val_accuracy: 0.8550\n","Epoch 36/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3391 - accuracy: 0.8607 - val_loss: 0.3515 - val_accuracy: 0.8575\n","Epoch 37/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3387 - accuracy: 0.8618 - val_loss: 0.3510 - val_accuracy: 0.8562\n","Epoch 38/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3384 - accuracy: 0.8607 - val_loss: 0.3506 - val_accuracy: 0.8575\n","Epoch 39/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3384 - accuracy: 0.8606 - val_loss: 0.3500 - val_accuracy: 0.8562\n","Epoch 40/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3381 - accuracy: 0.8599 - val_loss: 0.3500 - val_accuracy: 0.8562\n","Epoch 41/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3380 - accuracy: 0.8614 - val_loss: 0.3496 - val_accuracy: 0.8562\n","Epoch 42/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3376 - accuracy: 0.8608 - val_loss: 0.3492 - val_accuracy: 0.8587\n","Epoch 43/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3377 - accuracy: 0.8610 - val_loss: 0.3496 - val_accuracy: 0.8575\n","Epoch 44/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3375 - accuracy: 0.8617 - val_loss: 0.3484 - val_accuracy: 0.8550\n","Epoch 45/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3371 - accuracy: 0.8610 - val_loss: 0.3486 - val_accuracy: 0.8587\n","Epoch 46/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3373 - accuracy: 0.8617 - val_loss: 0.3485 - val_accuracy: 0.8562\n","Epoch 47/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3371 - accuracy: 0.8603 - val_loss: 0.3490 - val_accuracy: 0.8587\n","Epoch 48/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3368 - accuracy: 0.8615 - val_loss: 0.3483 - val_accuracy: 0.8575\n","Epoch 49/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3369 - accuracy: 0.8583 - val_loss: 0.3491 - val_accuracy: 0.8587\n","Epoch 50/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3368 - accuracy: 0.8606 - val_loss: 0.3487 - val_accuracy: 0.8562\n","Epoch 51/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3364 - accuracy: 0.8604 - val_loss: 0.3490 - val_accuracy: 0.8575\n","Epoch 52/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3366 - accuracy: 0.8599 - val_loss: 0.3487 - val_accuracy: 0.8562\n","Epoch 53/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3363 - accuracy: 0.8604 - val_loss: 0.3483 - val_accuracy: 0.8537\n","Epoch 54/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3362 - accuracy: 0.8610 - val_loss: 0.3485 - val_accuracy: 0.8587\n","Epoch 55/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3362 - accuracy: 0.8614 - val_loss: 0.3478 - val_accuracy: 0.8562\n","Epoch 56/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3360 - accuracy: 0.8606 - val_loss: 0.3479 - val_accuracy: 0.8550\n","Epoch 57/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3358 - accuracy: 0.8608 - val_loss: 0.3484 - val_accuracy: 0.8575\n","Epoch 58/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3359 - accuracy: 0.8625 - val_loss: 0.3481 - val_accuracy: 0.8550\n","Epoch 59/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3357 - accuracy: 0.8615 - val_loss: 0.3480 - val_accuracy: 0.8575\n","Epoch 60/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3356 - accuracy: 0.8617 - val_loss: 0.3490 - val_accuracy: 0.8550\n","Epoch 61/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3356 - accuracy: 0.8597 - val_loss: 0.3481 - val_accuracy: 0.8562\n","Epoch 62/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3354 - accuracy: 0.8625 - val_loss: 0.3474 - val_accuracy: 0.8562\n","Epoch 63/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3355 - accuracy: 0.8597 - val_loss: 0.3480 - val_accuracy: 0.8550\n","Epoch 64/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3351 - accuracy: 0.8621 - val_loss: 0.3485 - val_accuracy: 0.8562\n","Epoch 65/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3352 - accuracy: 0.8629 - val_loss: 0.3480 - val_accuracy: 0.8575\n","Epoch 66/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3353 - accuracy: 0.8619 - val_loss: 0.3487 - val_accuracy: 0.8562\n","Epoch 67/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3352 - accuracy: 0.8607 - val_loss: 0.3486 - val_accuracy: 0.8562\n","Epoch 68/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3353 - accuracy: 0.8617 - val_loss: 0.3480 - val_accuracy: 0.8550\n","Epoch 69/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3350 - accuracy: 0.8615 - val_loss: 0.3484 - val_accuracy: 0.8575\n","Epoch 70/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8604 - val_loss: 0.3489 - val_accuracy: 0.8587\n","Epoch 71/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3347 - accuracy: 0.8618 - val_loss: 0.3480 - val_accuracy: 0.8575\n","Epoch 72/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3347 - accuracy: 0.8610 - val_loss: 0.3481 - val_accuracy: 0.8550\n","Epoch 73/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3349 - accuracy: 0.8619 - val_loss: 0.3479 - val_accuracy: 0.8550\n","Epoch 74/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3346 - accuracy: 0.8611 - val_loss: 0.3478 - val_accuracy: 0.8575\n","Epoch 75/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3349 - accuracy: 0.8624 - val_loss: 0.3480 - val_accuracy: 0.8575\n","Epoch 76/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3347 - accuracy: 0.8625 - val_loss: 0.3480 - val_accuracy: 0.8550\n","Epoch 77/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8614 - val_loss: 0.3481 - val_accuracy: 0.8550\n","Epoch 78/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3345 - accuracy: 0.8624 - val_loss: 0.3474 - val_accuracy: 0.8537\n","Epoch 79/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3343 - accuracy: 0.8610 - val_loss: 0.3481 - val_accuracy: 0.8562\n","Epoch 80/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3343 - accuracy: 0.8628 - val_loss: 0.3480 - val_accuracy: 0.8575\n","Epoch 81/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3342 - accuracy: 0.8629 - val_loss: 0.3474 - val_accuracy: 0.8550\n","Epoch 82/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3344 - accuracy: 0.8615 - val_loss: 0.3475 - val_accuracy: 0.8562\n","Epoch 83/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3342 - accuracy: 0.8618 - val_loss: 0.3495 - val_accuracy: 0.8575\n","Epoch 84/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3343 - accuracy: 0.8633 - val_loss: 0.3478 - val_accuracy: 0.8587\n","Epoch 85/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8626 - val_loss: 0.3475 - val_accuracy: 0.8562\n","Epoch 86/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3339 - accuracy: 0.8626 - val_loss: 0.3472 - val_accuracy: 0.8537\n","Epoch 87/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3342 - accuracy: 0.8614 - val_loss: 0.3477 - val_accuracy: 0.8562\n","Epoch 88/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3338 - accuracy: 0.8624 - val_loss: 0.3482 - val_accuracy: 0.8550\n","Epoch 89/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8624 - val_loss: 0.3477 - val_accuracy: 0.8562\n","Epoch 90/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8622 - val_loss: 0.3474 - val_accuracy: 0.8575\n","Epoch 91/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8639 - val_loss: 0.3474 - val_accuracy: 0.8575\n","Epoch 92/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3338 - accuracy: 0.8632 - val_loss: 0.3475 - val_accuracy: 0.8550\n","Epoch 93/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3339 - accuracy: 0.8635 - val_loss: 0.3468 - val_accuracy: 0.8550\n","Epoch 94/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3340 - accuracy: 0.8608 - val_loss: 0.3479 - val_accuracy: 0.8575\n","Epoch 95/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3338 - accuracy: 0.8625 - val_loss: 0.3479 - val_accuracy: 0.8550\n","Epoch 96/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3337 - accuracy: 0.8614 - val_loss: 0.3478 - val_accuracy: 0.8575\n","Epoch 97/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3339 - accuracy: 0.8626 - val_loss: 0.3475 - val_accuracy: 0.8587\n","Epoch 98/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3338 - accuracy: 0.8621 - val_loss: 0.3469 - val_accuracy: 0.8562\n","Epoch 99/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3337 - accuracy: 0.8625 - val_loss: 0.3474 - val_accuracy: 0.8550\n","Epoch 100/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3337 - accuracy: 0.8632 - val_loss: 0.3479 - val_accuracy: 0.8575\n","Epoch 101/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3335 - accuracy: 0.8624 - val_loss: 0.3476 - val_accuracy: 0.8562\n","Epoch 102/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3336 - accuracy: 0.8617 - val_loss: 0.3481 - val_accuracy: 0.8575\n","Epoch 103/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3338 - accuracy: 0.8622 - val_loss: 0.3471 - val_accuracy: 0.8575\n","Epoch 104/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3336 - accuracy: 0.8619 - val_loss: 0.3474 - val_accuracy: 0.8575\n","Epoch 105/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3336 - accuracy: 0.8614 - val_loss: 0.3479 - val_accuracy: 0.8550\n","Epoch 106/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3336 - accuracy: 0.8633 - val_loss: 0.3477 - val_accuracy: 0.8587\n","Epoch 107/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3335 - accuracy: 0.8625 - val_loss: 0.3481 - val_accuracy: 0.8550\n","Epoch 108/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3334 - accuracy: 0.8621 - val_loss: 0.3471 - val_accuracy: 0.8562\n","Epoch 109/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3334 - accuracy: 0.8622 - val_loss: 0.3474 - val_accuracy: 0.8562\n","Epoch 110/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3335 - accuracy: 0.8615 - val_loss: 0.3472 - val_accuracy: 0.8575\n","Epoch 111/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8612 - val_loss: 0.3479 - val_accuracy: 0.8550\n","Epoch 112/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3337 - accuracy: 0.8615 - val_loss: 0.3481 - val_accuracy: 0.8575\n","Epoch 113/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8639 - val_loss: 0.3473 - val_accuracy: 0.8550\n","Epoch 114/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3334 - accuracy: 0.8624 - val_loss: 0.3475 - val_accuracy: 0.8575\n","Epoch 115/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8626 - val_loss: 0.3479 - val_accuracy: 0.8575\n","Epoch 116/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8619 - val_loss: 0.3476 - val_accuracy: 0.8587\n","Epoch 117/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8615 - val_loss: 0.3486 - val_accuracy: 0.8600\n","Epoch 118/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3331 - accuracy: 0.8633 - val_loss: 0.3485 - val_accuracy: 0.8575\n","Epoch 119/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3331 - accuracy: 0.8626 - val_loss: 0.3494 - val_accuracy: 0.8587\n","Epoch 120/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3334 - accuracy: 0.8619 - val_loss: 0.3489 - val_accuracy: 0.8550\n","Epoch 121/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3331 - accuracy: 0.8626 - val_loss: 0.3481 - val_accuracy: 0.8550\n","Epoch 122/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3330 - accuracy: 0.8618 - val_loss: 0.3480 - val_accuracy: 0.8562\n","Epoch 123/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3331 - accuracy: 0.8640 - val_loss: 0.3475 - val_accuracy: 0.8575\n","Epoch 124/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3329 - accuracy: 0.8625 - val_loss: 0.3476 - val_accuracy: 0.8562\n","Epoch 125/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3329 - accuracy: 0.8622 - val_loss: 0.3478 - val_accuracy: 0.8562\n","Epoch 126/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3327 - accuracy: 0.8632 - val_loss: 0.3481 - val_accuracy: 0.8562\n","Epoch 127/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3327 - accuracy: 0.8619 - val_loss: 0.3476 - val_accuracy: 0.8587\n","Epoch 128/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3330 - accuracy: 0.8637 - val_loss: 0.3479 - val_accuracy: 0.8550\n","Epoch 129/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3327 - accuracy: 0.8629 - val_loss: 0.3476 - val_accuracy: 0.8575\n","Epoch 130/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3329 - accuracy: 0.8617 - val_loss: 0.3473 - val_accuracy: 0.8562\n","Epoch 131/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8640 - val_loss: 0.3481 - val_accuracy: 0.8562\n","Epoch 132/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8628 - val_loss: 0.3478 - val_accuracy: 0.8587\n","Epoch 133/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8622 - val_loss: 0.3483 - val_accuracy: 0.8600\n","Epoch 134/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8632 - val_loss: 0.3470 - val_accuracy: 0.8587\n","Epoch 135/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8621 - val_loss: 0.3472 - val_accuracy: 0.8587\n","Epoch 136/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8625 - val_loss: 0.3479 - val_accuracy: 0.8575\n","Epoch 137/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8629 - val_loss: 0.3487 - val_accuracy: 0.8600\n","Epoch 138/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8628 - val_loss: 0.3480 - val_accuracy: 0.8575\n","Epoch 139/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8624 - val_loss: 0.3482 - val_accuracy: 0.8575\n","Epoch 140/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8633 - val_loss: 0.3478 - val_accuracy: 0.8600\n","Epoch 141/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8617 - val_loss: 0.3486 - val_accuracy: 0.8562\n","Epoch 142/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8625 - val_loss: 0.3487 - val_accuracy: 0.8550\n","Epoch 143/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8624 - val_loss: 0.3479 - val_accuracy: 0.8562\n","Epoch 144/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8624 - val_loss: 0.3485 - val_accuracy: 0.8550\n","Epoch 145/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8629 - val_loss: 0.3482 - val_accuracy: 0.8562\n","Epoch 146/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8639 - val_loss: 0.3487 - val_accuracy: 0.8525\n","Epoch 147/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8636 - val_loss: 0.3490 - val_accuracy: 0.8575\n","Epoch 148/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8618 - val_loss: 0.3480 - val_accuracy: 0.8575\n","Epoch 149/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8633 - val_loss: 0.3481 - val_accuracy: 0.8587\n","Epoch 150/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8636 - val_loss: 0.3480 - val_accuracy: 0.8550\n","Epoch 151/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8629 - val_loss: 0.3488 - val_accuracy: 0.8575\n","Epoch 152/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8642 - val_loss: 0.3483 - val_accuracy: 0.8587\n","Epoch 153/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8628 - val_loss: 0.3486 - val_accuracy: 0.8575\n","Epoch 154/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8625 - val_loss: 0.3500 - val_accuracy: 0.8550\n","Epoch 155/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8639 - val_loss: 0.3489 - val_accuracy: 0.8562\n","Epoch 156/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8644 - val_loss: 0.3489 - val_accuracy: 0.8537\n","Epoch 157/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8619 - val_loss: 0.3495 - val_accuracy: 0.8575\n","Epoch 158/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8640 - val_loss: 0.3484 - val_accuracy: 0.8550\n","Epoch 159/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8635 - val_loss: 0.3491 - val_accuracy: 0.8550\n","Epoch 160/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8631 - val_loss: 0.3483 - val_accuracy: 0.8562\n","Epoch 161/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8626 - val_loss: 0.3496 - val_accuracy: 0.8587\n","Epoch 162/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8642 - val_loss: 0.3491 - val_accuracy: 0.8575\n","Epoch 163/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8640 - val_loss: 0.3495 - val_accuracy: 0.8575\n","Epoch 164/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8625 - val_loss: 0.3493 - val_accuracy: 0.8575\n","Epoch 165/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8635 - val_loss: 0.3491 - val_accuracy: 0.8562\n","Epoch 166/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8625 - val_loss: 0.3491 - val_accuracy: 0.8575\n","Epoch 167/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8650 - val_loss: 0.3494 - val_accuracy: 0.8550\n","Epoch 168/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8639 - val_loss: 0.3495 - val_accuracy: 0.8550\n","Epoch 169/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8633 - val_loss: 0.3493 - val_accuracy: 0.8612\n","Epoch 170/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8621 - val_loss: 0.3497 - val_accuracy: 0.8550\n","Epoch 171/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8628 - val_loss: 0.3496 - val_accuracy: 0.8562\n","Epoch 172/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8632 - val_loss: 0.3497 - val_accuracy: 0.8562\n","Epoch 173/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8614 - val_loss: 0.3506 - val_accuracy: 0.8550\n","Epoch 174/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8642 - val_loss: 0.3495 - val_accuracy: 0.8587\n","Epoch 175/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8636 - val_loss: 0.3499 - val_accuracy: 0.8562\n","Epoch 176/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8631 - val_loss: 0.3496 - val_accuracy: 0.8600\n","Epoch 177/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8635 - val_loss: 0.3495 - val_accuracy: 0.8587\n","Epoch 178/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8636 - val_loss: 0.3489 - val_accuracy: 0.8600\n","Epoch 179/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8633 - val_loss: 0.3509 - val_accuracy: 0.8562\n","Epoch 180/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8631 - val_loss: 0.3496 - val_accuracy: 0.8587\n","Epoch 181/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8640 - val_loss: 0.3500 - val_accuracy: 0.8550\n","Epoch 182/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8640 - val_loss: 0.3498 - val_accuracy: 0.8600\n","Epoch 183/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8639 - val_loss: 0.3494 - val_accuracy: 0.8587\n","Epoch 184/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8635 - val_loss: 0.3494 - val_accuracy: 0.8612\n","Epoch 185/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8635 - val_loss: 0.3496 - val_accuracy: 0.8587\n","Epoch 186/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8642 - val_loss: 0.3508 - val_accuracy: 0.8587\n","Epoch 187/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8631 - val_loss: 0.3504 - val_accuracy: 0.8625\n","Epoch 188/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8642 - val_loss: 0.3505 - val_accuracy: 0.8550\n","Epoch 189/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8625 - val_loss: 0.3495 - val_accuracy: 0.8612\n","Epoch 190/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8633 - val_loss: 0.3513 - val_accuracy: 0.8600\n","Epoch 191/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8633 - val_loss: 0.3501 - val_accuracy: 0.8600\n","Epoch 192/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8631 - val_loss: 0.3507 - val_accuracy: 0.8525\n","Epoch 193/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8643 - val_loss: 0.3491 - val_accuracy: 0.8587\n","Epoch 194/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8626 - val_loss: 0.3499 - val_accuracy: 0.8600\n","Epoch 195/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8637 - val_loss: 0.3503 - val_accuracy: 0.8600\n","Epoch 196/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8644 - val_loss: 0.3497 - val_accuracy: 0.8587\n","Epoch 197/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8635 - val_loss: 0.3496 - val_accuracy: 0.8575\n","Epoch 198/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8633 - val_loss: 0.3502 - val_accuracy: 0.8587\n","Epoch 199/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8636 - val_loss: 0.3502 - val_accuracy: 0.8575\n","Epoch 200/200\n","225/225 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8646 - val_loss: 0.3503 - val_accuracy: 0.8562\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f03eedd2e10>"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"lJHw1-5ZSXbO"},"source":["### 7. Predict the results using 0.5 as a threshold"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CAnG4judSXbO","executionInfo":{"status":"ok","timestamp":1606008279365,"user_tz":360,"elapsed":55832,"user":{"displayName":"Bhavin Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP8kt4VFEDIIcPCxa1ZEDORGzYvFZvILuDA5C--g=s64","userId":"18232631185571279481"}},"outputId":"9d4dc41c-c489-4cc7-f8e5-6d91e843cbe9"},"source":["# Predict class returns 0 and 1. This will automatically takes care of the threshold.\n","# I also did it using the lambda function, but this is simpler.\n","Y_train_pred = model.predict_classes(X_train, batch_size=32, verbose=0)\n","Y_test_pred = model.predict_classes(X_test, batch_size=32, verbose=0)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-28-a838f7c875a9>:3: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n","Instructions for updating:\n","Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sejbWOUbSXbO"},"source":["### 8. Print Accuracy Score and Confusion Matrix"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f_aDNm6USXbO","executionInfo":{"status":"ok","timestamp":1606008279736,"user_tz":360,"elapsed":56195,"user":{"displayName":"Bhavin Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP8kt4VFEDIIcPCxa1ZEDORGzYvFZvILuDA5C--g=s64","userId":"18232631185571279481"}},"outputId":"6d123bc3-7800-46c4-fccf-6ec9ab496c74"},"source":["_, accuracy_train = model.evaluate(X_train, np.asarray(y_train), verbose=0)\n","print('Accuracy Train : %.2f' % (accuracy_train*100))\n","_, accuracy_test = model.evaluate(X_test, np.asarray(y_test), verbose = 0)\n","print('Accuracy Test : %.2f' % (accuracy_test*100))"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Accuracy Train : 86.29\n","Accuracy Test : 85.85\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BRcPvkDu4k6A","executionInfo":{"status":"ok","timestamp":1606008279737,"user_tz":360,"elapsed":56188,"user":{"displayName":"Bhavin Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP8kt4VFEDIIcPCxa1ZEDORGzYvFZvILuDA5C--g=s64","userId":"18232631185571279481"}},"outputId":"548f634e-1e0a-41b5-a610-4842fc62cb4f"},"source":["\n","print('Recall_score (Train): ' + str(recall_score(y_train.values,Y_train_pred)))\n","print('Precision_score (Train): ' + str(precision_score(y_train.values, Y_train_pred)))\n","print('F-score (Train):' + str(f1_score(y_train.values,Y_train_pred)))\n","confusion_matrix(y_train.values, Y_train_pred)"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Recall_score (Train): 0.523370233702337\n","Precision_score (Train): 0.7254901960784313\n","F-score (Train):0.6080743122543766\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["array([[6052,  322],\n","       [ 775,  851]])"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wf8Q5cey542N","executionInfo":{"status":"ok","timestamp":1606008279738,"user_tz":360,"elapsed":56181,"user":{"displayName":"Bhavin Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP8kt4VFEDIIcPCxa1ZEDORGzYvFZvILuDA5C--g=s64","userId":"18232631185571279481"}},"outputId":"ac669016-bbf5-4774-b4e6-9c1ce2d97430"},"source":["\n","print('Recall_score (Test): ' + str(recall_score(y_test.values,Y_test_pred)))\n","print('Precision_score (Test): ' + str(precision_score(y_test.values, Y_test_pred)))\n","print('F-score (Test): ' + str(f1_score(y_test.values,Y_test_pred)))\n","confusion_matrix(y_test.values, Y_test_pred)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["Recall_score (Test): 0.5255474452554745\n","Precision_score (Test): 0.7105263157894737\n","F-score (Test): 0.6041958041958042\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["array([[1501,   88],\n","       [ 195,  216]])"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"D4Z7LrKCY7xM","executionInfo":{"status":"ok","timestamp":1606008279738,"user_tz":360,"elapsed":56174,"user":{"displayName":"Bhavin Shah","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgP8kt4VFEDIIcPCxa1ZEDORGzYvFZvILuDA5C--g=s64","userId":"18232631185571279481"}}},"source":[""],"execution_count":31,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FBG_72luZFRH"},"source":["**Summary and Addtional Resullts**\n","\n","- Tried Various optimizer, found adam is the best optimizer.\n","- Tried 1,2,3 hidden layers. 2 Hidden Layers with relu is giving the best results.\n","- 1st hidden layer with 6 units and 2nd hidden layer with 3 units giving the best results.\n","- Tried relu, tanh, swish activation functions in hidden layers. Relu and Swish results are the best. Chose relu for the final model.\n","- Sigmoid is the best activation function for the output layker.\n","- Some additional results (Average over 3 runs):\n","  - 1st HL activation function (1st HL Units): 2nd HL activation function (2nd HL Units): F1 Score\n","  - Relu (6) : Relu (6) : 0.586\n","  - Swish (6) : Relu (6) : 0.581\n","  - Swish (6) : Swish(6): 0.587\n","  - Relu (12) : Relu(6)  :0.585\n","  - Swish (12) : Relu(6) : 0.589\n","  - Swish (12) : Swish(6) : 0.584\n","  - ***Relu (6) : Relu (3) : 0.595***\n","  - Relu (16) : Relu (8) : Relu (4) : 0.575\n","  - Relu (16) : Relu (8) : 0.587\n","  - Relu (8) : Relu (4) : 0.584\n","  - ***Swish (6) : Swish (3) : 0.592***\n","  - Relu (6) : tanh (3): 0.577"]},{"cell_type":"markdown","metadata":{"id":"F8TiYyw6jfb2"},"source":[""]}]}